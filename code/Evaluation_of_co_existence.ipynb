{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QB5fO93uEIbz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import KFold\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from numpy import asarray\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#https://github.com/chamarh/drebin_dataset\n",
        "import numpy as np\n",
        "from numpy import genfromtxt \n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kRtMjY7EO0F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "file_path = '/content/NEW2.csv'\n",
        "signaldata = pd.read_csv(file_path)\n",
        "DF=pd.DataFrame(signaldata)\n",
        "DF.rename(columns = {'classs':'class'}, inplace = True)\n",
        "DF.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLCEpduWERyg"
      },
      "outputs": [],
      "source": [
        "class_count_0, class_count_1 = DF['class'].value_counts()\n",
        "class_0 = DF[DF['class'] == 0]\n",
        "class_1 = DF[DF['class'] == 1]\n",
        "#print('class 0:', class_0.shape)\n",
        "#print('class 1:', class_1.shape)\n",
        "class_0_under = class_0.sample(class_count_1)\n",
        "balanced_data = pd.concat([class_0_under, class_1], axis=0)\n",
        "#print(balanced_data)\n",
        "#print(balanced_data['class'])\n",
        "#print(\"total class of 1 and0:\",balanced_data['class'].value_counts())\n",
        "balanced_data['class'].value_counts().plot(kind='bar', title='count (class)')\n",
        "malware=balanced_data[balanced_data['class'] == 1]\n",
        "benign=balanced_data[balanced_data['class'] ==0 ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iGUEpcQSEVye"
      },
      "outputs": [],
      "source": [
        "features = [i for i in DF.columns if i not in ['class']]\n",
        "original_Xtrain=balanced_data[features].values\n",
        "target = balanced_data['class']\n",
        "Ytrain=balanced_data['class'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWX4RF_8Eebr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_recall_curve \n",
        "from sklearn import svm,model_selection, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "def fpr_s(y_true,y_pred):\n",
        "   CM = confusion_matrix(y_true, y_pred)\n",
        "   TN = CM[0][0]\n",
        "   FN = CM[1][0]\n",
        "   TP = CM[1][1]\n",
        "   FP = CM[0][1]\n",
        "   return FP/(FP+TN)\n",
        "def fnr_s(y_true,y_pred):\n",
        "   CM = confusion_matrix(y_true, y_pred)\n",
        "   TN = CM[0][0]\n",
        "   FN = CM[1][0]\n",
        "   TP = CM[1][1]\n",
        "   FP = CM[0][1]\n",
        "   return FN/(FN+TP)\n",
        "#f2_score function\n",
        "def f2_score(y_true, y_pred):\n",
        "    y_true, y_pred, = np.array(y_true), np.array(y_pred)\n",
        "    return fbeta_score(y_true, y_pred, beta=2, average='binary')\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "def score_model(X, y, kf):\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    roc_auc_scores=[]\n",
        "    f2_scores=[]\n",
        "    fpr_scores=[]\n",
        "    fnr_scores=[]\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        model=RandomForestClassifier(n_estimators=9, random_state=111)\n",
        "        model.fit(original_Xtrain, Ytrain)\n",
        "        #model = DecisionTreeClassifier(criterion='gini')\n",
        "        #model.fit(original_Xtrain, Ytrain)\n",
        "        #model =LogisticRegression(C=0.1)\n",
        "        #model.fit(original_Xtrain, Ytrain)\n",
        "        #model=svm.SVC(C=1.0, kernel='rbf', degree=9, gamma=2,max_iter = 1e5)\n",
        "        #model.fit(original_Xtrain, Ytrain)\n",
        "        #model=KNeighborsClassifier(n_neighbors=5, metric='jaccard')\n",
        "        #model.fit(original_Xtrain, Ytrain)\n",
        "        #model=linear_model.Perceptron()\n",
        "        #model.fit(original_Xtrain, Ytrain)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "        precision_scores.append(precision_score(y_test, y_pred))\n",
        "        recall_scores.append(recall_score(y_test, y_pred))\n",
        "        f1_scores.append(f1_score(y_test, y_pred))\n",
        "        roc_auc_scores.append(roc_auc_score(y_test,y_pred))\n",
        "        f2_scores.append(f2_score(y_test, y_pred))\n",
        "        fpr_scores.append(fpr_s(y_test,y_pred))\n",
        "        fnr_scores.append(fnr_s(y_test,y_pred))\n",
        "    print('accuracy','precision','recall(tpr)', \"f1 score\",'roc_auc_score','fpr score','fnr')\n",
        "    print( np.mean(accuracy_scores),np.mean(precision_scores),np.mean(recall_scores),np.mean(f1_scores),\n",
        "       np.mean(roc_auc_scores),np.mean(fpr_scores),np.mean(fnr_scores))\n",
        "\n",
        "print(\"original data performance metrices\")\n",
        "score_model(original_Xtrain,Ytrain,kf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ANN **"
      ],
      "metadata": {
        "id": "Y9iJcF_Hxb2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature=genfromtxt('/content/NEW2.csv', delimiter=',', usecols=(i for i in range(0,150)),dtype=float,skip_header=1)\n",
        "class_value=genfromtxt('/content/NEW2.csv', delimiter=',', usecols=(-1), dtype=str, skip_header=1)"
      ],
      "metadata": {
        "id": "ZNVSWsjrnmP7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing of data s=malware --> 1, b=begnin --> 0\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "#feature_std = StandardScaler().fit_transform(feature)\n",
        "class_value = LabelEncoder().fit_transform(class_value)  \n",
        "print(class_value)"
      ],
      "metadata": {
        "id": "YNErGKAJn0My"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_value_cat = np_utils.to_categorical(class_value, num_classes=2)\n",
        "print(class_value_cat)"
      ],
      "metadata": {
        "id": "J0gkHcRdn4f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(feature, class_value_cat,test_size=0.25, random_state=1)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "Y3qGmlQTmvYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=np.array(x_train)\n",
        "x_test=np.array(x_test)\n",
        "y_train=np.array(y_train)\n",
        "y_test=np.array(y_test)"
      ],
      "metadata": {
        "id": "GOGPC2pym6e0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[1].shape)\n",
        "print(y_train[1].shape)"
      ],
      "metadata": {
        "id": "-PZ7bvgtm85s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of features = x_train.shape[1]\n",
        "print(x_train.shape[1])\n",
        "# number of classes "
      ],
      "metadata": {
        "id": "Z-bG2QwFnA8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#build the model\n",
        "model = Sequential ([\n",
        "    Input(shape=(x_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    #sigmoid is a logistic regression function, softmax transform a vector into a vector of probabilities\n",
        "    Dense(2, activation='softmax')  \n",
        "])\n",
        "model.summary()\n",
        "print(model.output_shape)\n",
        "print(model.compute_output_signature)"
      ],
      "metadata": {
        "id": "jnhkhAKdnDt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n"
      ],
      "metadata": {
        "id": "-fDVK4i8nNgG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile our model\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#model.compile(Adam(lr=.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.compile(optimizer=sgd, loss='mean_squared_error', metrics=['accuracy'])\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LoeYMmN-nQv9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=x_train, y=y_train, batch_size=10, epochs=100, shuffle=True, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "2UoD3B1ZnQye"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}